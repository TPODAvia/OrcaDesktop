services:
  zenohd:
    image: eclipse/zenoh:latest
    container_name: zenohd
    network_mode: host
    command: >
      -c /etc/zenoh/router.json5
    volumes:
      - ./zenoh/router.json5:/etc/zenoh/router.json5:ro
    restart: unless-stopped

  zenoh_bridge_ros2dds:
    image: eclipse/zenoh-bridge-ros2dds:latest
    container_name: zenoh-bridge-ros2dds
    network_mode: host
    depends_on:
      - zenohd
    environment:
      RMW_IMPLEMENTATION: rmw_cyclonedds_cpp
      ROS_DISTRO: humble
    command: >
      -c /etc/zenoh/bridge-dds.json5
    volumes:
      - ./zenoh/bridge-dds.json5:/etc/zenoh/bridge-dds.json5:ro
    restart: unless-stopped

  ros2_cli:
    build:
      context: /home/rover2/OrcaDesktops
      dockerfile: docker/ros2_cli.Dockerfile
    image: orca-ros2-cli:latest
    container_name: ros2-cli
    network_mode: host
    depends_on:
      - zenohd
      - zenoh_bridge_ros2dds
    tty: true
    stdin_open: true
    working_dir: /root/colcon_ws
    volumes:
      - ../colcon_ws:/root/colcon_ws
    environment:
      DEBIAN_FRONTEND: noninteractive
      ROS_DISTRO: humble
      ROS_DOMAIN_ID: "1"                    # <- you said you want DOMAIN_ID=1
      RMW_IMPLEMENTATION: rmw_cyclonedds_cpp
      INFLUX_URL: "http://127.0.0.1:8086"
      INFLUX_TOKEN: ${INFLUX_TOKEN:-supersecrettoken}
      INFLUX_ORG: ${INFLUX_ORG:-orca}
      INFLUX_BUCKET: ${INFLUX_BUCKET:-rmf}
      MEASUREMENT: rmf_robot_state
    command:
      - bash
      - -lc
      - |
        set -e
        source /opt/ros/humble/setup.bash
        if [ -f /root/colcon_ws/install/setup.bash ]; then
          source /root/colcon_ws/install/setup.bash
        fi
        echo "ðŸš€ Starting rmf_manager_cloud server (ROS_DOMAIN_ID=$ROS_DOMAIN_ID)..."
        ros2 launch rmf_manager_cloud server.launch.py
    restart: "no"

  influxdb:
    image: influxdb:2.7
    container_name: influxdb
    network_mode: host
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: ${INFLUX_USERNAME:-admin}
      DOCKER_INFLUXDB_INIT_PASSWORD: ${INFLUX_PASSWORD:-admin12345}
      DOCKER_INFLUXDB_INIT_ORG: ${INFLUX_ORG:-orca}
      DOCKER_INFLUXDB_INIT_BUCKET: ${INFLUX_BUCKET:-rmf}
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: ${INFLUX_TOKEN:-supersecrettoken}
    volumes:
      - ./influxdb/data:/var/lib/influxdb2
      - ./influxdb/config:/etc/influxdb2
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://127.0.0.1:8086/health"]
      interval: 5s
      timeout: 3s
      retries: 20
      start_period: 30s
    restart: unless-stopped

  grafana:
    image: grafana/grafana:10.4.5
    container_name: grafana
    network_mode: host
    depends_on:
      - influxdb
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-admin}
      GF_USERS_ALLOW_SIGN_UP: "false"
    volumes:
      - ./grafana/data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    restart: unless-stopped

  go2rtc:
    image: ghcr.io/alexxit/go2rtc:latest
    container_name: go2rtc
    network_mode: host        # easiest in your setup, like zenohd etc.
    restart: unless-stopped
    volumes:
      - ./go2rtc/go2rtc.yaml:/config/go2rtc.yaml:ro

  frigate:
    container_name: frigate
    image: ghcr.io/blakeblackshear/frigate:stable-tensorrt
    privileged: true
    restart: unless-stopped
    shm_size: "2g"
    network_mode: host

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    environment:
      NVIDIA_VISIBLE_DEVICES: "all"
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility,video"

    devices:
      - /dev/bus/usb:/dev/bus/usb   # ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶ÐµÐ½ Coral, Ð¼Ð¾Ð¶Ð½Ð¾ ÑƒÐ±Ñ€Ð°Ñ‚ÑŒ
      - /dev/dri:/dev/dri           # hw-accel Ð²Ð¸Ð´ÐµÐ¾

    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ./frigate/config.yml:/config/config.yml:ro
      - ./frigate/storage:/media/frigate
      - ./frigate/models:/config/models
      - type: tmpfs
        target: /tmp/cache
        tmpfs:
          size: 1000000000

  portainer:
    image: portainer/portainer-ce:latest
    container_name: portainer
    restart: unless-stopped
    ports:
      - "9000:9000"  # Web UI
      - "8000:8000"  # Edge agent (can be removed if not needed)
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./portainer-data:/data